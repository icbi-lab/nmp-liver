"""Helper functions to compare between groups of samples

This module contains high-level abstractions to linear models
and functions to compare scores with different methods
"""

from typing import List, Mapping, Optional, Sequence
from . import lm
from . import pl
from . import compute_scores
import numpy as np
import pandas as pd
from tqdm.contrib.concurrent import process_map
import itertools
from ..util import split_anndata, fdr_correction, log2_fc
from anndata import AnnData

TOOLS = {
    "progeny": compute_scores.run_progeny,
    "dorothea": compute_scores.run_dorothea,
    "cytosig": compute_scores.run_cytosig,
}


def _run_tool(adata, tools):
    """Run a certain tool on an anndata object.

    Helper function executed in parallel on a chunked anndata object.
    """
    res = {}
    for tool in tools:
        res[tool] = TOOLS[tool](adata)
    return res


def prepare_dataset(
    id_: str,
    *,
    dataset: AnnData,
    cell_type_column: str,
    tools: Sequence[str] = ("progeny", "cytosig"),
    column_to_test: str,
    n_jobs: int = 1,
    **kwargs,
) -> Mapping[str, Mapping[str, AnnData]]:
    """Split anndata by cell-type and run the different signature enrichment methods

    Parameters
    ----------
    id_
        string identifier of the current dataset
    dataset
        anndata object to test
    cell_type_column
        column in adata.obs that contains the cell-type annotation
    tools
        tools to run on the dataset. Supported are `dorothea`, `progeny`, `cytosig`
    column_to_test
        Column containing the dependent variable
    n_jobs
        Number of worker threads to use. Parallelizes by cell-type.
    **kwargs
        Not used, but allows to pass parameters via a config dictionary that contains additional parameters

    Returns
    -------
    Dictionary [tool : (Dictionary [cell-type : anndata])]
    """

    # subset list to available tools
    tools = [t for t in tools if t in TOOLS]

    print(f"Preparing dataset for {id_}:")
    dataset = dataset[
        (dataset.obs[cell_type_column] != "other")
        & ~pd.isnull(dataset.obs[column_to_test])
        & (dataset.obs[column_to_test] != "nan"),
        :,
    ].copy()

    dataset.obs[column_to_test] = pd.Categorical(
        dataset.obs[column_to_test].astype(str)
    )

    print(f"\tSplitting anndata by {cell_type_column}:")
    adata_by_cell_type = split_anndata(dataset, cell_type_column)
    res_by_cell_type = process_map(
        _run_tool,
        adata_by_cell_type.values(),
        itertools.repeat(tools),
        max_workers=n_jobs,
    )

    all_adatas = {}
    for tool in tools:
        all_adatas[tool] = {}
        for ct, tmp_res in zip(adata_by_cell_type, res_by_cell_type):
            all_adatas[tool][ct] = tmp_res[tool]

    return all_adatas


def compare_signatures(
    id_: str,
    all_adatas: Mapping[str, Mapping[str, AnnData]],
    *,
    pseudobulk_group_by: List[str],
    column_to_test: str,
    lm_covariate_str: str,
    contrasts: str,
    n_jobs: int = 1,
    **kwargs,
) -> Mapping[str, pd.DataFrame]:
    """Compare signature enrichment using linear model.

    Parameters
    ----------
    id_
        string identifier of the current dataset
    all_adatas
        adatas split by tool and cell-type as generated by :func:`prepare_datasets`
    pseudobulk_group_by
        columns in `.obs` that are used group cells into pseudobulk. See :func:`scanpy_helpers.pseudobulk.pseudobulk`.
    column_to_test
        column that contains the variable to test
    lm_covariate_str
        Patsy model string that is appended to the linear model formula. E.g. `+ dataset`.
    contrasts
        a patsy contrast included in to linear model formula. May be `Sum`, `Treatment`, or `Treatment('<base level>')`.
        See https://www.statsmodels.org/devel/contrasts.html for more details.
    **kwargs
        Not used, but allows to pass parameters via a config dictionary that contains additional parameters

    Returns
    -------
    A dictionary [tool : results data frame]
    """
    print(f"Performing comparison for {id_}:")
    all_results = {}
    for tool in all_adatas:
        print(f"\tRunning tests for {tool}:")
        tmp_res = lm.lm_test_all(
            all_adatas[tool],
            groupby=pseudobulk_group_by,
            column_to_test=column_to_test,
            lm_covariate_str=lm_covariate_str,
            contrasts=contrasts,
            n_jobs=n_jobs,
        )
        all_results[tool] = tmp_res

    return all_results
